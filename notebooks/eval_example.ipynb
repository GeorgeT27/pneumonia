{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../src/pgm')\n",
    "sys.path.append('../morphomnist')\n",
    "from typing import Dict, IO, Optional, Tuple, List\n",
    "import os\n",
    "import gc\n",
    "import copy\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pgm.train_pgm import setup_dataloaders, preprocess\n",
    "from pgm.flow_pgm import MorphoMNISTPGM\n",
    "\n",
    "class Hparams:\n",
    "    def update(self, dict):\n",
    "        for k, v in dict.items():\n",
    "            setattr(self, k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the code needed for running evaluation should already be here:\n",
    "\n",
    "(i) https://github.com/biomedia-mira/causal-gen/blob/main/src/pgm/train_cf.py\n",
    "\n",
    "(ii) https://huggingface.co/spaces/mira-causality/counterfactuals/blob/main/app_utils.py\n",
    "\n",
    "I whipped up a more concise eval example below, hope it helps :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MorphoMNIST\n",
    "1. Load parent predictors - classifier/regressor for each parent in $\\mathbf{pa}_\\mathbf{x}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_path = '/workspace/causal-gen/checkpoints/f_a_s_r/aux_60k-aux/checkpoint.pt'\n",
    "print(f'\\nLoading predictor checkpoint: {predictor_path}')\n",
    "predictor_checkpoint = torch.load(predictor_path)\n",
    "predictor_args = Hparams()\n",
    "predictor_args.update(predictor_checkpoint['hparams'])\n",
    "assert predictor_args.dataset == 'morphomnist'\n",
    "predictor = MorphoMNISTPGM(predictor_args).cuda()\n",
    "predictor.load_state_dict(predictor_checkpoint['ema_model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load PGM - Flow-based causal mechanisms for each node in the causal graph (except for $\\mathbf{x}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgm_path = '/workspace/causal-gen/checkpoints/f_a_s_r/pgm_60k-pgmg/checkpoint.pt'\n",
    "print(f'\\nLoading PGM checkpoint: {pgm_path}')\n",
    "pgm_checkpoint = torch.load(pgm_path)\n",
    "pgm_args = Hparams()\n",
    "pgm_args.update(pgm_checkpoint['hparams'])\n",
    "assert pgm_args.dataset == 'morphomnist'\n",
    "pgm = MorphoMNISTPGM(pgm_args).cuda()\n",
    "pgm.load_state_dict(pgm_checkpoint['ema_model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Load HVAE - causal mechanism for the image $\\mathbf{x}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vae(vae_path):\n",
    "    print(f'\\nLoading VAE checkpoint: {vae_path}')\n",
    "    vae_checkpoint = torch.load(vae_path)\n",
    "    vae_args = Hparams()\n",
    "    vae_args.update(vae_checkpoint['hparams'])\n",
    "    vae_args.data_dir = 'your dataset dir here'\n",
    "\n",
    "    # init model\n",
    "    assert vae_args.hps == 'morphomnist'\n",
    "    if not hasattr(vae_args, 'vae'):\n",
    "        vae_args.vae = 'simple'\n",
    "\n",
    "    if vae_args.vae == 'hierarchical':\n",
    "        from vae import HVAE\n",
    "        vae = HVAE(vae_args).cuda()\n",
    "    elif vae_args.vae == 'simple':\n",
    "        from simple_vae import VAE\n",
    "        vae = VAE(vae_args).cuda()\n",
    "    else:\n",
    "        NotImplementedError\n",
    "    vae.load_state_dict(vae_checkpoint['ema_model_state_dict'])\n",
    "    return vae, vae_args\n",
    "model_name = 'mimic192'\n",
    "vae_path = '/workspace/causal-gen/checkpoints/f_a_s_r/'+model_name+'/checkpoint.pt'\n",
    "vae, vae_args = load_vae(vae_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UKBB/MIMIC\n",
    "1. Load parent predictors, PGM and HVAE similar to above\n",
    "2. Run counterfactual evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_counterfactuals(original_images, cf_images, original_pa, cf_pa, num_samples=8):\n",
    "    \"\"\"\n",
    "    Visualize original images vs their counterfactuals using TRUE / SCM-generated parent labels.\n",
    "\n",
    "    Rows:\n",
    "      1. Original image with disease (finding)\n",
    "      2. Counterfactual image with intervened disease (finding)\n",
    "      3. Direct Effect (Original - Counterfactual) heatmap (diverging colormap)\n",
    "    \"\"\"\n",
    "    n = min(num_samples, len(original_images), len(cf_images))\n",
    "    fig, axes = plt.subplots(3, n, figsize=(2.2 * n, 6.0))\n",
    "\n",
    "    # Ensure axes is 2D even if n == 1\n",
    "    if n == 1:\n",
    "        axes = axes.reshape(3, 1)\n",
    "\n",
    "    # Precompute raw difference in float (keep signed range)\n",
    "    # original_images and cf_images are in [0,255] after preprocessing\n",
    "    diff = cf_images[:n].float() - original_images[:n].float()  # shape (n,1,H,W) or (n,H,W)\n",
    "    \n",
    "    # Use 75th percentile of absolute difference to set color scale (handles outliers)\n",
    "    # This makes the visualization clearer by not letting extreme outliers dominate the scale\n",
    "    abs_diff = diff.abs()\n",
    "    percentile_75 = torch.quantile(abs_diff, 0.75).item()\n",
    "    dmax = percentile_75 + 1e-6\n",
    "    vmin, vmax = -dmax, dmax\n",
    "\n",
    "    for i in range(n):\n",
    "        # Row 0: Original\n",
    "        orig_img = original_images[i].squeeze().detach().cpu().numpy()\n",
    "        axes[0, i].imshow(orig_img, cmap='gray', vmin=0, vmax=255)\n",
    "        # Extract disease label (finding)\n",
    "        orig_finding_tensor = original_pa[\"finding\"][i]\n",
    "        # Handle both scalar and one-hot encoded disease labels\n",
    "        if orig_finding_tensor.dim() > 0 and orig_finding_tensor.numel() > 1:\n",
    "            orig_disease = orig_finding_tensor.argmax().item()\n",
    "        else:\n",
    "            orig_disease = int(orig_finding_tensor.item())\n",
    "        axes[0, i].set_title(f'Original\\nDisease: {orig_disease}', fontsize=9)\n",
    "        axes[0, i].axis('off')\n",
    "\n",
    "        # Row 1: Counterfactual\n",
    "        cf_img = cf_images[i].squeeze().detach().cpu().numpy()\n",
    "        axes[1, i].imshow(cf_img, cmap='gray', vmin=0, vmax=255)\n",
    "        cf_finding_tensor = cf_pa[\"finding\"][i]\n",
    "        # Handle both scalar and one-hot encoded disease labels\n",
    "        if cf_finding_tensor.dim() > 0 and cf_finding_tensor.numel() > 1:\n",
    "            cf_disease = cf_finding_tensor.argmax().item()\n",
    "        else:\n",
    "            cf_disease = int(cf_finding_tensor.item())\n",
    "        axes[1, i].set_title(f'Counterfactual\\nDisease: {cf_disease}', fontsize=9)\n",
    "        axes[1, i].axis('off')\n",
    "\n",
    "        # Row 2: Difference (CF - O)\n",
    "        diff_img = diff[i].squeeze().detach().cpu().numpy()\n",
    "        im = axes[2, i].imshow(diff_img, cmap='RdBu_r', vmin=vmin, vmax=vmax)\n",
    "        axes[2, i].set_title('Direct Effect\\n(CF - O)', fontsize=9)\n",
    "        axes[2, i].axis('off')\n",
    "\n",
    "    # Add a single colorbar for the difference row\n",
    "    plt.tight_layout(rect=[0,0,0.92,1])\n",
    "    cbar_ax = fig.add_axes([0.93, 0.12, 0.015, 0.22])\n",
    "    fig.colorbar(im, cax=cbar_ax, label='Intensity Î” (CF - O) [clipped at p75]')\n",
    "    plt.savefig('/workspace/causal-gen/notebooks/disease_counterfactuals.png')\n",
    "    plt.show()\n",
    "    \n",
    "def vae_preprocess(pa: Dict[str, Tensor], parents_order: Optional[list] = None, input_res: int = 192, device: Optional[torch.device] = None) -> Tensor:\n",
    "    \"\"\"Construct VAE conditioning tensor.\n",
    "    Args:\n",
    "        pa: dict of parent tensors (each (B,C) or (B,)).\n",
    "        parents_order: explicit ordering list; if None uses pa.keys() insertion order.\n",
    "        input_res: spatial size to tile to.\n",
    "        device: target device.\n",
    "    Returns:\n",
    "        Tensor of shape (B, sum(C_i), input_res, input_res)\n",
    "    \"\"\"\n",
    "    order = parents_order if parents_order is not None else list(pa.keys())\n",
    "    feats = []\n",
    "    for k in order:\n",
    "        if k not in pa:\n",
    "            raise KeyError(f\"Parent '{k}' missing from provided dict. Keys={list(pa.keys())}\")\n",
    "        v = pa[k]\n",
    "        if v is None:\n",
    "            raise ValueError(f\"Parent {k} is None; ensure batch was preprocessed (split='l').\")\n",
    "        if v.dim() == 1:\n",
    "            v = v.unsqueeze(-1)  # (B,1)\n",
    "        feats.append(v.float())\n",
    "    cat = torch.cat(feats, dim=1)\n",
    "    cat = cat[..., None, None].repeat(1, 1, *(input_res,) * 2)\n",
    "    if device is not None:\n",
    "        cat = cat.to(device)\n",
    "    return cat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cf_disease_visualization(vae, pgm, predictor, dataloaders, num_samples=9, te_cf: bool = False):\n",
    "    \"\"\"\n",
    "    Generate and visualize counterfactuals on MIMIC by intervening on disease_label (finding).\n",
    "\n",
    "    Selection:\n",
    "      - Choose ~num_samples/2 from each disease class (0,1) if available.\n",
    "      - If not enough of one class, fill remaining from other class.\n",
    "    Intervention:\n",
    "      - Flip disease label: 0 -> 1, 1 -> 0\n",
    "\n",
    "    Visualization:\n",
    "      - Use TRUE original and counterfactual parent labels (finding) from SCM / counterfactual generation.\n",
    "      - Disease (finding) comes from original_pa and cf_pa (PGM outputs), not predictor image-based outputs.\n",
    "    \"\"\"\n",
    "    vae.eval(); pgm.eval(); predictor.eval()\n",
    "\n",
    "    assert num_samples >= 2, \"num_samples should be >= 2 for balancing across 2 disease classes\"\n",
    "\n",
    "    # ----------------- Prepare batch -----------------\n",
    "    full_batch = next(iter(dataloaders['test']))\n",
    "    # Move entire batch to GPU (temporarily) to filter\n",
    "    tmp = {k: v.clone() for k,v in full_batch.items()}\n",
    "    tmp = preprocess(tmp)  # now on CUDA\n",
    "\n",
    "    finding = tmp['finding']  # (B, 1) binary label\n",
    "    finding_labels = finding.squeeze(-1).long()  # (B,) get class indices (0 or 1)\n",
    "    class_indices = [(finding_labels == c).nonzero(as_tuple=True)[0] for c in range(2)]\n",
    "\n",
    "    per_class = max(1, num_samples // 2)\n",
    "    remainder = num_samples - per_class * 2\n",
    "\n",
    "    sel_parts = []\n",
    "    for c in range(2):\n",
    "        idxs = class_indices[c][:per_class]\n",
    "        sel_parts.append(idxs)\n",
    "    # Distribute remainder starting from class 0\n",
    "    if remainder > 0:\n",
    "        for c in range(2):\n",
    "            if remainder == 0: break\n",
    "            extra_pool = class_indices[c][per_class:per_class+1]\n",
    "            if extra_pool.numel() > 0:\n",
    "                sel_parts[c] = torch.cat([sel_parts[c], extra_pool])\n",
    "                remainder -= 1\n",
    "    sel_idx = torch.cat(sel_parts)\n",
    "    sel_idx = sel_idx[:num_samples]\n",
    "\n",
    "    batch = {k: full_batch[k][sel_idx.cpu()] for k in full_batch.keys()}\n",
    "    batch = preprocess(batch)  # final selected minibatch to CUDA\n",
    "\n",
    "    device = batch['x'].device\n",
    "    parents_order = getattr(vae, 'args', getattr(pgm, 'args', None))\n",
    "    parents_order = getattr(parents_order, 'parents_x', ['finding','age','sex','race'])  # fallback\n",
    "\n",
    "    original_x = batch['x']\n",
    "    original_pa = {k: v for k, v in batch.items() if k != 'x'}\n",
    "\n",
    "    # ----------------- Build intervention (flip disease label) -----------------\n",
    "    if 'finding' not in original_pa:\n",
    "        raise KeyError(\"'finding' not found in batch parents for MIMIC dataset.\")\n",
    "    \n",
    "    finding = original_pa['finding']  # (B, 1) binary label\n",
    "    # Flip the disease label: 0 -> 1, 1 -> 0\n",
    "    finding_cf = 1 - finding\n",
    "    \n",
    "    do = {'finding': finding_cf}\n",
    "    do = {k: v.clone() for k, v in do.items()}  # ensure shape\n",
    "    do = preprocess(do)  # ensure shape/device\n",
    "\n",
    "    # ----------------- Generate counterfactual parents via SCM -----------------\n",
    "    cf_pa = pgm.counterfactual(obs=original_pa, intervention=do, num_particles=1)\n",
    "\n",
    "    # Ensure cf_pa contains flipped finding (overwrite if SCM kept same due to design)\n",
    "    cf_pa['finding'] = finding_cf\n",
    "\n",
    "    # ----------------- Prepare VAE parent tensors -----------------\n",
    "    _pa_dict = {k: original_pa[k].clone() for k in original_pa}\n",
    "    _cf_pa_dict = {k: cf_pa[k].clone() for k in cf_pa}\n",
    "    input_res = getattr(getattr(vae, 'args', None), 'input_res', 192)\n",
    "    _pa = vae_preprocess(_pa_dict, parents_order=parents_order, input_res=input_res, device=device)\n",
    "    _cf_pa = vae_preprocess(_cf_pa_dict, parents_order=parents_order, input_res=input_res, device=device)\n",
    "\n",
    "    # Sanity checks\n",
    "    assert _pa.shape[0] == original_x.shape[0] == _cf_pa.shape[0], \"Batch size mismatch in parent conditioning tensors\"\n",
    "\n",
    "    # ----------------- Latent abduction -----------------\n",
    "    t_z = t_u = 0.1  # sampling temps\n",
    "    z = vae.abduct(original_x, parents=_pa, t=t_z)\n",
    "    if hasattr(vae, 'cond_prior') and vae.cond_prior:\n",
    "        # For (H)VAE with conditional prior, z is list of dicts -> extract latent tensors\n",
    "        z = [z[i]['z'] for i in range(len(z))]\n",
    "\n",
    "    rec_loc, rec_scale = vae.forward_latents(z, parents=_pa)\n",
    "    u = (original_x - rec_loc) / rec_scale.clamp(min=1e-12)\n",
    "\n",
    "    if hasattr(vae, 'cond_prior') and vae.cond_prior and te_cf:\n",
    "        cf_z = vae.abduct(x=original_x, parents=_pa, cf_parents=_cf_pa, alpha=0.65)\n",
    "        cf_loc, cf_scale = vae.forward_latents(cf_z, parents=_cf_pa)\n",
    "    else:\n",
    "        cf_loc, cf_scale = vae.forward_latents(z, parents=_cf_pa)\n",
    "    cf_scale = cf_scale * t_u\n",
    "    cf_x = torch.clamp(cf_loc + cf_scale * u, min=-1, max=1)\n",
    "\n",
    "    # Displays\n",
    "    orig_display = ((original_x + 1) * 127.5).cpu()\n",
    "    cf_display = ((cf_x + 1) * 127.5).cpu()\n",
    "\n",
    "    visualize_counterfactuals(orig_display, cf_display, original_pa, cf_pa, num_samples)\n",
    "\n",
    "    return orig_display, cf_display, original_pa, cf_pa\n",
    "\n",
    "\n",
    "dataloaders = setup_dataloaders(pgm_args)\n",
    "_ = test_cf_disease_visualization(vae, pgm, predictor, dataloaders, num_samples=9, te_cf=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
